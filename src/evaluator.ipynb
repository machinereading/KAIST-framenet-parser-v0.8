{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "import modelio\n",
    "import feature_handler\n",
    "import masked_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data_vocab(training_data):\n",
    "    word_vocab_in_train, pos_vocab_in_train, frame_vocab_in_train, lu_vocab_in_train, fe_vocab_in_train = [],[],[],[], []\n",
    "    for tokens in training_data:\n",
    "        for t in tokens:\n",
    "            lu = t[12]\n",
    "            if lu != '_':\n",
    "                lu_vocab_in_train.append(lu)\n",
    "            frame = t[13]\n",
    "            if frame != '_':\n",
    "                frame_vocab_in_train.append(frame)\n",
    "            bio_fe = t[14]\n",
    "            if bio_fe != 'O':\n",
    "                fe = bio_fe.split('-')[1]\n",
    "    \n",
    "    lu_vocab_in_train = list(set(lu_vocab_in_train))\n",
    "    frame_vocab_in_train = list(set(frame_vocab_in_train))\n",
    "    fe_vocab_in_train = list(set(fe_vocab_in_train))\n",
    "    return lu_vocab_in_train, frame_vocab_in_train, fe_vocab_in_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class live(object):\n",
    "    \n",
    "    def __init__(self, language, word_to_ix, pos_to_ix, dp_to_ix, josa_to_ix, frame_to_ix, lu_to_ix, fe_to_ix, josa_onlyPOS, usingGPU):\n",
    "        self.usingGPU = usingGPU \n",
    "        self.josa_onlyPOS = josa_onlyPOS\n",
    "        self.language = language\n",
    "        \n",
    "        self.word_to_ix = word_to_ix\n",
    "        self.pos_to_ix = pos_to_ix\n",
    "        self.dp_to_ix = dp_to_ix\n",
    "        self.josa_to_ix = josa_to_ix\n",
    "        self.frame_to_ix = frame_to_ix\n",
    "        self.lu_to_ix = lu_to_ix\n",
    "        self.fe_to_ix = fe_to_ix\n",
    "        \n",
    "    def frame_evaluation():\n",
    "        pass\n",
    "    \n",
    "    def argument_evaluation(self, model, training_data, test_data):\n",
    "        \n",
    "        feature_extractor = feature_handler.extractor(self.language, self.josa_onlyPOS, self.usingGPU)\n",
    "        prepare = modelio.prepare(self.usingGPU) \n",
    "        tensor2tag = modelio.tensor2tag(self.frame_to_ix, self.fe_to_ix, self.usingGPU)\n",
    "        \n",
    "        lu_vocab_in_train, frame_vocab_in_train, fe_vocab_in_train = prepare_training_data_vocab(training_data)\n",
    "        \n",
    "        acc, total = 0,0\n",
    "        tp,fn,tn,fp, found = 0,0,0,0,0\n",
    "        for tokens in test_data:\n",
    "            sentence, pos, dp, lu, frame = prepare.prepare_sentence(tokens)\n",
    "            if lu in lu_vocab_in_train:\n",
    "                if frame in frame_vocab_in_train:\n",
    "                    sentence, pos, dp, lu, frame = prepare.prepare_sentence(tokens)\n",
    "                    target_position = feature_extractor.get_targetpositions(tokens)\n",
    "                    sentence_in = prepare.prepare_sequence(sentence, self.word_to_ix)\n",
    "                    pos_in = prepare.prepare_sequence(pos, self.pos_to_ix)\n",
    "                    dp_in = prepare.prepare_sequence(dp, self.dp_to_ix)\n",
    "#                     frame_in = prepare.prepare_ix(frame, self.frame_to_ix)\n",
    "#                     lu_in = prepare.prepare_ix(lu, self.lu_to_ix)\n",
    "                    positions = feature_extractor.get_argpositions(tokens)\n",
    "\n",
    "\n",
    "                    gold_spans = []\n",
    "                    for arg_position in positions:\n",
    "                        arg = arg_position[2]\n",
    "                        arg_in = prepare.prepare_ix(arg, self.fe_to_ix)\n",
    "                        josa = feature_extractor.get_josa(tokens, arg_position)\n",
    "                        last_dp = feature_extractor.get_last_dp(tokens, arg_position)\n",
    "\n",
    "                        josa_in = prepare.prepare_ix(josa, self.josa_to_ix)\n",
    "                        last_dp_in = prepare.prepare_ix(last_dp, self.dp_to_ix)\n",
    "\n",
    "                        if arg_position[2] != 'O':\n",
    "                            gold_span = {}\n",
    "                            arg_span = {}\n",
    "                            arg_span['begin'] = arg_position[0]\n",
    "                            arg_span['end'] = arg_position[1]\n",
    "                            gold_span['arg'] = arg\n",
    "                            gold_span['span'] = arg_span\n",
    "                            gold_span['arg_in'] = arg_in\n",
    "                            gold_span['josa_in'] = josa_in\n",
    "                            gold_span['last_dp_in'] = last_dp_in\n",
    "                            gold_spans.append(gold_span)\n",
    "\n",
    "                    for gold_arg in gold_spans:                \n",
    "                        model.zero_grad()\n",
    "                        model.hidden_lstm_tok = model.init_hidden_lstm_tok()\n",
    "                        model.hidden_lstm_tgt = model.init_hidden_lstm_tgt()\n",
    "                        model.hidden_lstm_arg = model.init_hidden_lstm_arg()\n",
    "                        arg_span = gold_arg['span']\n",
    "                        arg_in = gold_arg['arg_in']\n",
    "                        josa_in = gold_arg['josa_in']\n",
    "                        last_dp_in = gold_arg['last_dp_in']\n",
    "                        tag_scores = model(sentence_in, pos_in, dp_in, josa_in, last_dp_in, arg_in, target_position, arg_span, lu, frame, sentence)\n",
    "\n",
    "\n",
    "                        gold = gold_arg['arg']\n",
    "                        score, pred = tensor2tag.get_fe_by_tensor(tag_scores)\n",
    "\n",
    "    #                     print(gold, pred)\n",
    "                        if pred != 'O':\n",
    "                            if pred == gold:\n",
    "                                tp += 1\n",
    "                            else:\n",
    "                                fp += 1\n",
    "                        if gold != 'O':\n",
    "                            if pred == 'O':\n",
    "                                fn += 1\n",
    "                            else: \n",
    "                                found += 1\n",
    "                        if pred == gold:\n",
    "                            acc += 1\n",
    "                            total += 1\n",
    "                        else:\n",
    "                            total += 1\n",
    "    #             break\n",
    "        if tp == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = tp / (tp+fp)\n",
    "        if found == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = found / (found+fn)\n",
    "        if precision == 0 or recall == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = 2 * (precision*recall) / (precision+recall)\n",
    "        precision = round(precision, 4)\n",
    "        recall = round(recall, 4)\n",
    "        f1 = round(f1, 4)\n",
    "        if acc != 0:\n",
    "            accuracy = acc / total\n",
    "        else:\n",
    "            accuracy = 0\n",
    "            \n",
    "        return precision, recall, f1, accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
