{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import posChanger\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "from koreanframenet import kfn\n",
    "import re\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_identification_ko(conll):\n",
    "    result = []\n",
    "    frame = 'None'\n",
    "    for i in conll:\n",
    "        #print(i[0], i[2], i[3])\n",
    "        lu1, lu2 = [],[]\n",
    "        #print(i)\n",
    "        lus =[]\n",
    "        lex = i[2].split('+')[0].split('/')[0]\n",
    "        pos = i[2].split('+')[0].split('/')[1]\n",
    "        pos = posChanger.posChanger(pos)\n",
    "        lemma = lex+'.'+pos\n",
    "        lu1 = kfn.lus_by_lemma(lemma)\n",
    "        #print(lu1)\n",
    "        \n",
    "        surfaceform = i[1]\n",
    "        spc = [',','.','!','?']\n",
    "        if len(surfaceform) > 1:\n",
    "            if surfaceform[-1] in spc:\n",
    "                surfaceform = re.sub('[,.?!]', '', surfaceform)\n",
    "        lu2 = kfn.lus_by_surfaceform(surfaceform)\n",
    "        lus = lu1+lu2\n",
    "        lus = list(set(lus))\n",
    "        \n",
    "        pos = i[4].split('+')[0]\n",
    "        pos = posChanger.posChanger(pos)\n",
    "        lu_candis = []\n",
    "        if len(lus) > 0:\n",
    "            for lc in lus:\n",
    "                lu_pos = lc.split('.')[1]\n",
    "                #print('pos', pos, lu_pos)\n",
    "                if pos == lu_pos:\n",
    "                    lu_candi_list = lc.split('.')[:-1]\n",
    "                    lu_candi = '.'.join(lu_candi_list)\n",
    "                    lu_candis.append(lu_candi)\n",
    "                    #print(lu_candi)\n",
    "                    #if surfaceform[0] == lu_candi[0]:\n",
    "                        #lu_candis.append(lu_candi)\n",
    "        lu_candis = list(set(lu_candis))\n",
    "#         print(lu_candis)\n",
    "        if len(lu_candis) > 0:\n",
    "            lu = False\n",
    "            max = 0\n",
    "            for j in lu_candis:\n",
    "                lexu_list = kfn.lus_by_lu(j)\n",
    "                for k in lexu_list:\n",
    "                    count = len(k['ko_annotation_id'])\n",
    "                    if count > max:\n",
    "                        lu = j\n",
    "                        max = count                \n",
    "            lu_dict = {}\n",
    "            lu_dict['token_id'] = i[0]\n",
    "            lu_dict['lu'] = lu\n",
    "            lu_with_frame = []\n",
    "            for j in lus:\n",
    "                lexu = j.split('.')[0] + '.' + j.split('.')[1]\n",
    "                if lexu == lu:\n",
    "                    lu_with_frame.append(j)\n",
    "            lu_dict['lu_with_frame'] = lu_with_frame\n",
    "            if lu != False:\n",
    "                result.append(lu_dict)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_identification_en(conll, enlu):\n",
    "    result = []\n",
    "    new_conll = deepcopy(conll)\n",
    "    \n",
    "    targets = []\n",
    "    for token_ix in range(len(new_conll)):\n",
    "        token = new_conll[token_ix]\n",
    "        pos = token[5]\n",
    "        if pos.startswith('N'):\n",
    "            pos = 'n'\n",
    "        elif pos.startswith('V'):\n",
    "            pos = 'v'\n",
    "        elif pos.startswith('RB'):\n",
    "            pos = 'a'        \n",
    "            \n",
    "        lem = token[3]+'.'+pos\n",
    "        \n",
    "        for lu in enlu:\n",
    "            if lem == lu:\n",
    "                tu = (token_ix, lu)\n",
    "                targets.append(tu)\n",
    "                break\n",
    "    for i in targets:\n",
    "        target_ix, lu = i[0],i[1]\n",
    "        \n",
    "        new_conll = deepcopy(conll)\n",
    "        \n",
    "        for token_ix in range(len(new_conll)):\n",
    "            \n",
    "            token = new_conll[token_ix]\n",
    "            if token_ix == target_ix:\n",
    "                token.append(lu)\n",
    "            else:\n",
    "                token.append('_')\n",
    "        result.append(new_conll)\n",
    "    return result\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
