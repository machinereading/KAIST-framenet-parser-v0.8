{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe36f05abd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from optparse import OptionParser\n",
    "import torch.autograd as autograd\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "sys.path.insert(0,'../')\n",
    "sys.path.insert(0,'./src')\n",
    "import preprocessor\n",
    "import dataio\n",
    "import feature_handler\n",
    "import modelio\n",
    "import masked_softmax\n",
    "import evaluator\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support as f1score\n",
    "start_time = time.time()\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dir_path = os.path.dirname( os.path.abspath( __file__ ) )\n",
    "except:\n",
    "    dir_path = './'\n",
    "frameid_model = dir_path+'/../model/frameid-lstm-ko.pt'\n",
    "\n",
    "language = 'ko'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### CONFIGURATION ###\n",
      "\n",
      "{'batch_size': 64,\n",
      " 'dropout_rate': 0.01,\n",
      " 'hidden_dim': 64,\n",
      " 'language': 'ko',\n",
      " 'learning_rate': 0.001,\n",
      " 'lstm_depth': 2,\n",
      " 'lstm_dim': 64,\n",
      " 'lstm_input_dim': 64,\n",
      " 'lu_dim': 64,\n",
      " 'lu_pos_dim': 5,\n",
      " 'num_epochs': 100,\n",
      " 'pos_dim': 4,\n",
      " 'pretrained_embedding_dim': 300,\n",
      " 'token_dim': 60,\n",
      " 'using_GPU': True,\n",
      " 'using_exemplar': False,\n",
      " 'using_pretrained_embedding': True}\n"
     ]
    }
   ],
   "source": [
    "if language == 'ko':\n",
    "    PRETRAINED_DIM = 300\n",
    "else:\n",
    "    PRETRAINED_DIM = 100\n",
    "\n",
    "configuration = {'token_dim': 60,\n",
    "                 'hidden_dim': 64,\n",
    "                 'pos_dim': 4,\n",
    "                 'lu_dim': 64,\n",
    "                 'lu_pos_dim': 5,\n",
    "                 'lstm_input_dim': 64,\n",
    "                 'lstm_dim': 64,\n",
    "                 'lstm_depth': 2,\n",
    "                 'hidden_dim': 64,\n",
    "                 'num_epochs': 100,\n",
    "                 'learning_rate': 0.001,\n",
    "                 'dropout_rate': 0.01,\n",
    "                 'using_GPU': True,\n",
    "                 'using_pretrained_embedding': True,\n",
    "                 'using_exemplar': False,\n",
    "                 'pretrained_embedding_dim': PRETRAINED_DIM,\n",
    "                 'language': language,\n",
    "                 'batch_size': 64}\n",
    "# print('\\n### CONFIGURATION ###\\n')\n",
    "# pprint.pprint(configuration)\n",
    "\n",
    "#Hyper-parameters\n",
    "usingGPU = configuration['using_GPU']\n",
    "TOKDIM= configuration['token_dim']\n",
    "POSDIM = configuration['pos_dim']\n",
    "LUDIM = configuration['lu_dim']\n",
    "LPDIM = configuration['lu_pos_dim']\n",
    "INPDIM = TOKDIM + POSDIM\n",
    "LSTMINPDIM = configuration['lstm_input_dim']\n",
    "LSTMDIM = configuration['lstm_dim']\n",
    "LSTMDEPTH = configuration['lstm_depth']\n",
    "HIDDENDIM = configuration['hidden_dim']\n",
    "NUM_EPOCHS = configuration['num_epochs']\n",
    "learning_rate = configuration['learning_rate']\n",
    "DROPOUT_RATE = configuration['dropout_rate']\n",
    "batch_size = configuration['batch_size']\n",
    "USE_WV = configuration['using_pretrained_embedding']\n",
    "USE_EXEM = configuration['using_exemplar']\n",
    "PRETRAINED_DIM = configuration['pretrained_embedding_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### loading data now...\n",
      "# training_data\n",
      " - number of sentences: 3220\n",
      " - number of annotations: 12431 \n",
      "\n",
      "# test_data\n",
      " - number of sentences: 1124\n",
      " - number of annotations: 4382 \n",
      "\n",
      "# dev_data\n",
      " - number of sentences: 183\n",
      " - number of annotations: 624 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data, test_data, dev_data, exemplar_data = preprocessor.load_data(language, USE_EXEM)\n",
    "preprocessor.data_stat(language, USE_EXEM)\n",
    "\n",
    "lufrmap, frargmap = preprocessor.read_map(language)\n",
    "token2wv_dir = dir_path+'/../data/'+language+'.token2wv.json'\n",
    "with open(token2wv_dir,'r') as f:\n",
    "    token2wv = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_index():\n",
    "    word_to_ix = {}\n",
    "    pos_to_ix = {}\n",
    "    frame_to_ix = {}\n",
    "    lu_to_ix = {}\n",
    "    word_to_ix['UNSEEN'] = 0\n",
    "    word_vocab, pos_vocab, frame_vocab, lu_vocab = [],[],[],[]\n",
    "    all_data = training_data + test_data + dev_data\n",
    "    for tokens in all_data:\n",
    "        for t in tokens:\n",
    "            word = t[1]\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                word_vocab.append(word)\n",
    "            pos = t[5]\n",
    "            if pos not in pos_to_ix:\n",
    "                pos_to_ix[pos] = len(pos_to_ix)\n",
    "                pos_vocab.append(pos)\n",
    "            frame = t[13]\n",
    "            if frame != '_':\n",
    "                if frame not in frame_to_ix:\n",
    "                    frame_to_ix[frame] = len(frame_to_ix)\n",
    "                    frame_vocab.append(frame)\n",
    "            lu = t[12]\n",
    "            if lu != '_':\n",
    "                if lu not in lu_to_ix:\n",
    "                    lu_to_ix[lu] = len(lu_to_ix)\n",
    "                    lu_vocab.append(lu)\n",
    "    return word_to_ix, pos_to_ix, frame_to_ix, lu_to_ix\n",
    "word_to_ix, pos_to_ix, frame_to_ix, lu_to_ix = prepare_index()\n",
    "WORD_VOCAB_SIZE, POS_VOCAB_SIZE, LU_VOCAB_SIZE, FRAME_VOCAB_SIZE = len(word_to_ix), len(pos_to_ix), len(lu_to_ix), len(frame_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vocab():\n",
    "    word_vocab, pos_vocab, frame_vocab, lu_vocab = [],[],[],[]\n",
    "    for tokens in training_data:\n",
    "        for t in tokens:\n",
    "            lu = t[12]\n",
    "            if lu != '_':\n",
    "                lu_vocab.append(lu)\n",
    "    lu_vocab = list(set(lu_vocab))\n",
    "    return lu_vocab\n",
    "lu_vocab = prepare_vocab()\n",
    "\n",
    "def prepare_sentence(tokens):\n",
    "    sentence, pos, lu, frame = [],[], False, False\n",
    "    for token in tokens:\n",
    "        w,p,l,f = token[1],token[5],token[12],token[13]\n",
    "        sentence.append(w)\n",
    "        pos.append(p)\n",
    "        if token[12] != '_':\n",
    "            lu, frame = token[12], token[13]\n",
    "    return sentence, pos, lu, frame\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    vocab = list(to_ix.keys())\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w in vocab:\n",
    "            idxs.append(to_ix[w])\n",
    "        else:\n",
    "            idxs.append(0)            \n",
    "    if usingGPU:\n",
    "        return torch.tensor(idxs).type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        return torch.tensor(idxs, dtype=torch.long)\n",
    "    \n",
    "def prepare_lu_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq if w != '_']\n",
    "    idxs = list(set(idxs))\n",
    "    if usingGPU:\n",
    "        return torch.tensor(idxs).type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        return torch.tensor(idxs, dtype=torch.long)\n",
    "        \n",
    "def prepare_ix(item, to_ix):\n",
    "    idxs = [ to_ix[item] ]\n",
    "    if usingGPU:\n",
    "        return torch.tensor(idxs).type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        return torch.tensor(idxs, dtype=torch.long)    \n",
    "\n",
    "def prepare_arg_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq if w != '_']\n",
    "    idxs = list(set(idxs))\n",
    "    if usingGPU:\n",
    "        return torch.tensor(idxs).type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        return torch.tensor(idxs, dtype=torch.long) \n",
    "\n",
    "def prepare_frame_vector(seq, to_ix):\n",
    "    if usingGPU:\n",
    "        frame_vector =  torch.zeros(len(to_ix)).type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        frame_vector =  torch.zeros(len(to_ix), dtype=torch.long)\n",
    "    for f in seq:\n",
    "        if f != '_':\n",
    "            fid = frame_to_ix[f]\n",
    "            frame_vector[fid] = 1\n",
    "    return frame_vector\n",
    "\n",
    "def get_targetpositions(tokens):\n",
    "    positions = []\n",
    "    lu = False\n",
    "    for i in tokens:\n",
    "        if i[12] != '_':\n",
    "            positions.append(int(i[0]))\n",
    "    positions = np.asarray(positions)\n",
    "    positions = torch.from_numpy(positions)\n",
    "    if usingGPU:\n",
    "        return positions.type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        return positions\n",
    "\n",
    "def get_target_span(sentence, targetpositions):\n",
    "    start, end = int(targetpositions[0]), int(targetpositions[-1])\n",
    "    span = {}\n",
    "    if start == 0: span['start'] = 0\n",
    "    else: span['start'] = start -1\n",
    "    if end == len(sentence): span['end'] = end+1\n",
    "    else: span['end'] = end+2\n",
    "    return span\n",
    "\n",
    "\n",
    "# # Masked Softmax\n",
    "def gen_mask(lu):\n",
    "    mask_list = []\n",
    "    frame_candis = lufrmap[lu]\n",
    "    for fr in frame_to_ix:\n",
    "#         print(frame_to_ix[fr])\n",
    "        if fr in frame_candis:\n",
    "            mask_list.append(1)\n",
    "        else:\n",
    "            mask_list.append(0)\n",
    "    mask_numpy = np.array(mask_list)\n",
    "    mask = torch.from_numpy(mask_numpy)\n",
    "    if usingGPU:\n",
    "        return mask.type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        return mask\n",
    "\n",
    "def masked_softmax(vec, mask, dim=-1):\n",
    "    mask = mask.float()\n",
    "    vec_masked = vec * mask + (1 / mask - 1)\n",
    "    vec_min = vec_masked.min(1)[0]\n",
    "    vec_exp = (vec - vec_min.unsqueeze(-1)).exp()\n",
    "    vec_exp = vec_exp * mask.float()\n",
    "    result = vec_exp / vec_exp.sum(1).unsqueeze(-1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        # define look-up embeddis for token, pos, and lu\n",
    "        self.token_embeddings = nn.Embedding(WORD_VOCAB_SIZE, TOKDIM)\n",
    "        self.pos_embeddings = nn.Embedding(POS_VOCAB_SIZE, POSDIM)\n",
    "        self.lu_embeddings = nn.Embedding(LU_VOCAB_SIZE, LUDIM)\n",
    "        self.word_embeddings = nn.Embedding(WORD_VOCAB_SIZE, PRETRAINED_DIM)\n",
    "               \n",
    "        # 1st LSTM network (bi-LSTM)\n",
    "        self.lstm_1 = nn.LSTM(INPDIM, HIDDENDIM//2, bidirectional=True, num_layers=LSTMDEPTH, dropout=DROPOUT_RATE)\n",
    "        self.hidden_lstm_1 = self.init_hidden_lstm_1()\n",
    "        \n",
    "        # 2nd LSTM network (LSTM)\n",
    "        self.hidden_lstm_2 = self.init_hidden_lstm_2()\n",
    "        self.lstm_2 = nn.LSTM(HIDDENDIM, HIDDENDIM, num_layers=LSTMDEPTH, dropout=DROPOUT_RATE)\n",
    "        \n",
    "        # Linear \n",
    "        self.target2lstminput = nn.Linear(INPDIM, LSTMINPDIM)\n",
    "        self.addwv2lstminput = nn.Linear(PRETRAINED_DIM+INPDIM, LSTMINPDIM)\n",
    "        self.target2hidden = nn.Linear(LSTMINPDIM+LUDIM, HIDDENDIM)\n",
    "        self.hidden2tag = nn.Linear(HIDDENDIM, tagset_size) \n",
    "    \n",
    "    def init_hidden_lstm_1(self):\n",
    "        if usingGPU:\n",
    "            return (torch.zeros(4, 1, HIDDENDIM//2).cuda(),\n",
    "                torch.zeros(4, 1, HIDDENDIM//2).cuda())\n",
    "        else:\n",
    "            return (torch.zeros(4, 1, HIDDENDIM//2),\n",
    "                torch.zeros(4, 1, HIDDENDIM//2))\n",
    "        \n",
    "    def init_hidden_lstm_2(self):\n",
    "        if usingGPU:\n",
    "            return (torch.zeros(2, 1, HIDDENDIM).cuda(),\n",
    "                torch.zeros(2, 1, HIDDENDIM).cuda())\n",
    "        else:\n",
    "            return (torch.zeros(2, 1, HIDDENDIM),\n",
    "                torch.zeros(2, 1, HIDDENDIM))\n",
    "    \n",
    "        \n",
    "    def forward(self, sentence, pos, targetpositions, lu, tokens):\n",
    "#         if USE_WV:\n",
    "#             word_embs = self.token_embeddings(sentence)\n",
    "#         else:\n",
    "#             word_embs = self.token_embeddings(sentence)\n",
    "        tok_embs = self.token_embeddings(sentence)\n",
    "        pos_embs = self.pos_embeddings(pos)\n",
    "        \n",
    "        lu_ix = prepare_ix(lu, lu_to_ix)\n",
    "        lu_embs = self.lu_embeddings(lu_ix)\n",
    "\n",
    "        # 1) input vector\n",
    "        if not USE_WV: #concat token and pos enbeddings \n",
    "            target_embeds = torch.cat((tok_embs, pos_embs), 1)\n",
    "            lstm_embeds = self.target2lstminput(target_embeds)\n",
    "        else: #concat token embedding and pretrained word embedding and pos embedding\n",
    "            word_embs = self.word_embeddings(sentence)\n",
    "            for i in range(len(tokens)):\n",
    "                if tokens[i] in token2wv:\n",
    "                    pretrained_wv = token2wv[tokens[i]].split(' ')\n",
    "                    pretrained_wv = np.array([float(x) for x in pretrained_wv])\n",
    "                    pretrained_wv = torch.from_numpy(pretrained_wv)\n",
    "                    word_embs[i] = pretrained_wv       \n",
    "            target_embeds = torch.cat((tok_embs, word_embs, pos_embs), 1)\n",
    "            lstm_embeds = self.addwv2lstminput(target_embeds)\n",
    "        \n",
    "        embeds = lstm_embeds.view(len(sentence), 1, -1)\n",
    "        embeds = F.relu(embeds)\n",
    "\n",
    "        # 2) first Bi-LSTM for token sequence\n",
    "        lstm_out_1, self.hidden_lstm_1 = self.lstm_1(\n",
    "            embeds, self.hidden_lstm_1)\n",
    "        span = get_target_span(sentence, targetpositions)\n",
    "        target_lstm = lstm_out_1[span['start']:span['end']]\n",
    "        \n",
    "        # 3) second LSTM for last hidden state for the context of LU (output: target vector)\n",
    "        lstm_out_2, self.hidden = self.lstm_2(\n",
    "            target_lstm, self.hidden_lstm_2)\n",
    "        target_vec = lstm_out_2[-1]\n",
    "\n",
    "        # 4) concate target vector with lu embedding\n",
    "        lu_vec = torch.cat( (target_vec, lu_embs) ,1)\n",
    "\n",
    "        # 5) linear\n",
    "        tag_space = self.target2hidden(lu_vec)\n",
    "        tag_space = F.relu(tag_space)\n",
    "        tag_space = self.hidden2tag(tag_space)\n",
    "\n",
    "        # 6) masked softmax\n",
    "        mask = gen_mask(lu)\n",
    "        tag_scores = masked_softmax(tag_space, mask)\n",
    "\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_by_tensor(t):\n",
    "    value, indices = t.max(1)\n",
    "    score = pow(10, value)\n",
    "    \n",
    "    pred = None\n",
    "    for frame, idx in frame_to_ix.items():\n",
    "        if idx == indices:\n",
    "            pred = frame\n",
    "            break\n",
    "    return score, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class frame_identifier():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def identifier(self, conll, model):\n",
    "        \n",
    "        score = 0\n",
    "        pred = '_'\n",
    "\n",
    "        sent = conll\n",
    "        for t in sent:\n",
    "            if t[13] != '_':\n",
    "                answer_lu = t[12]\n",
    "        if answer_lu in lu_vocab:\n",
    "            sentence, pos, lu, frame = prepare_sentence(sent)            \n",
    "            targetpositions = get_targetpositions(sent)\n",
    "            sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "            pos_in = prepare_sequence(pos, pos_to_ix)    \n",
    "            tag_scores = model(sentence_in,pos_in, targetpositions, lu, sentence)\n",
    "            score, pred = get_frame_by_tensor(tag_scores)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        return pred, score\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "# frame_identifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
