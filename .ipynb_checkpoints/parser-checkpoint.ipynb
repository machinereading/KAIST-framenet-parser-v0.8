{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### loading data now...\n",
      "### loading data now...\n",
      "### loading data now...\n",
      "\n",
      "### VOCAB SIZE\n",
      "# WORD_VOCAB_SIZE: 27227\n",
      "# POS_VOCAB_SIZE: 1037\n",
      "# DP_VOCAB_SIZE: 40\n",
      "# JOSA_VOCAB_SIZE: 87\n",
      "# LU_VOCAB_SIZE: 3892\n",
      "# FRAME_VOCAB_SIZE: 687\n",
      "# FE_VOCAB_SIZE: 739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from optparse import OptionParser\n",
    "from src import etri\n",
    "from src import targetid\n",
    "from copy import deepcopy\n",
    "from src import frameid_module_ko\n",
    "from src import frameid_module_en\n",
    "from src import argid_module_ko\n",
    "import torch\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_model_ko_dir = './model/frameid-lstm-ko.pt'\n",
    "fid_model_en_dir = './model/frameid-lstm-en.pt'\n",
    "argid_model_ko_dir = './model/argid-lstm-ko.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODE: parsing\n",
      "LANGUAGE: ko\n"
     ]
    }
   ],
   "source": [
    "optpr = OptionParser()\n",
    "optpr.add_option(\"--mode\", dest='mode', type='choice', choices=['train', 'test', 'parsing'], default='parsing')\n",
    "optpr.add_option(\"--lang\", dest='lang', type='choice', choices=['en', 'ko'], default='ko')\n",
    "optpr.add_option(\"--text\", dest='text')\n",
    "\n",
    "# (options, args) = optpr.parse_args()\n",
    "# parser_mode = options.mode\n",
    "# language = options.lang\n",
    "\n",
    "parser_mode = 'parsing'\n",
    "language = 'ko'\n",
    "print('\\nMODE:', parser_mode)\n",
    "print('LANGUAGE:', language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nlp(nlp):\n",
    "    conll= etri.getETRI_CoNLL2009(nlp)\n",
    "    pa = etri.phrase_parser(conll, nlp)\n",
    "    \n",
    "    return conll, pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/en.lufrmap.json') as f:\n",
    "        enlu = json.load(f)\n",
    "\n",
    "def target_identification(conll, language):\n",
    "    \n",
    "    result = []\n",
    "    if language == 'ko':\n",
    "        targets = targetid.target_identification_ko(conll)\n",
    "\n",
    "        for target in targets:        \n",
    "\n",
    "            target_id = target['token_id']\n",
    "            target_lemma = target['lu']\n",
    "            \n",
    "            old_conll = deepcopy(conll)\n",
    "            new_conll = []\n",
    "            for token_id in range(len(old_conll)):\n",
    "                token = old_conll[token_id]\n",
    "                if target_id == token_id:\n",
    "                    token.append(target_lemma)\n",
    "                    token.append('TARGET')\n",
    "                else:\n",
    "                    token.append('_')\n",
    "                    token.append('_')\n",
    "                \n",
    "            new_conll = deepcopy(old_conll)\n",
    "            result.append(new_conll)\n",
    "            new_conll = []\n",
    "            \n",
    "    else:\n",
    "        old_conll = deepcopy(conll)\n",
    "\n",
    "        targets = []\n",
    "        for token_ix in range(len(old_conll)):\n",
    "            token = old_conll[token_ix]\n",
    "            pos = token[5]\n",
    "            if pos.startswith('N'):\n",
    "                pos = 'n'\n",
    "            elif pos.startswith('V'):\n",
    "                pos = 'v'\n",
    "            elif pos.startswith('RB'):\n",
    "                pos = 'a'        \n",
    "\n",
    "            lem = token[3]+'.'+pos\n",
    "\n",
    "            for lu in enlu:\n",
    "                if lem == lu:\n",
    "                    tu = (token_ix, lu)\n",
    "                    targets.append(tu)\n",
    "                    break\n",
    "        for i in targets:\n",
    "            target_ix, lu = i[0],i[1]\n",
    "\n",
    "            new_conll = deepcopy(old_conll)\n",
    "\n",
    "            for token_ix in range(len(new_conll)):\n",
    "\n",
    "                token = new_conll[token_ix]\n",
    "                if token_ix == target_ix:\n",
    "                    token.append(lu)\n",
    "                    token.append('TARGET')\n",
    "                else:\n",
    "                    token.append('_')\n",
    "                    token.append('_')\n",
    "            result.append(new_conll)\n",
    "            \n",
    "            \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### loading data now...\n"
     ]
    }
   ],
   "source": [
    "from frameid_module_ko import LSTMTagger\n",
    "fid_model = torch.load(fid_model_ko_dir)\n",
    "ko_frame_ider = frameid_module_ko.frame_identifier()\n",
    "\n",
    "def frame_identification(conll_with_target, language):\n",
    "    if language == 'ko':\n",
    "        result = []\n",
    "        scores = []\n",
    "        for conll in conll_with_target:\n",
    "            \n",
    "            frame, score = ko_frame_ider.identifier(conll, fid_model)\n",
    "            \n",
    "            if frame != '_':\n",
    "                new_conll = deepcopy(conll)\n",
    "                score = score.item()*0.1\n",
    "                for token in new_conll:\n",
    "                    if token[12] != '_':\n",
    "                        token[13] = frame\n",
    "                    else:\n",
    "                        pass\n",
    "                result.append(new_conll)\n",
    "                scores.append(score)\n",
    "    return result, scores      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### loading data now...\n",
      "\n",
      "### VOCAB SIZE\n",
      "# WORD_VOCAB_SIZE: 27227\n",
      "# POS_VOCAB_SIZE: 1037\n",
      "# DP_VOCAB_SIZE: 40\n",
      "# JOSA_VOCAB_SIZE: 87\n",
      "# LU_VOCAB_SIZE: 3892\n",
      "# FRAME_VOCAB_SIZE: 687\n",
      "# FE_VOCAB_SIZE: 739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'argid_module_ko.LSTMTagger' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "from argid_module_ko import LSTMTagger\n",
    "argid_model = torch.load(argid_model_ko_dir)\n",
    "ko_arg_ider = argid_module_ko.arg_identifier()\n",
    "\n",
    "\n",
    "def arg_identification(conll_with_frame, language):\n",
    "    result = []\n",
    "    if language == 'ko':\n",
    "        new_conll_with_frame = deepcopy(conll_with_frame)\n",
    "\n",
    "        for p in pa:\n",
    "            target_id = p['predicate']['id']\n",
    "\n",
    "            for sent in new_conll_with_frame:\n",
    "                for token in sent:\n",
    "                    if token[0] == target_id:\n",
    "                        pass\n",
    "\n",
    "        for sent in new_conll_with_frame:\n",
    "            for token in sent:\n",
    "                if token[13] != '_':\n",
    "                    target_id = token[0]\n",
    "                token.append('O')\n",
    "\n",
    "            if target_id:\n",
    "                for p in pa:\n",
    "                    pred_id = p['predicate']['id']\n",
    "                    if target_id == pred_id:\n",
    "                        n = 0\n",
    "                        for arg in p['arguments']:\n",
    "                            arg_ids = arg['tokens']\n",
    "                            for arg_ix in range(len(arg_ids)):\n",
    "                                arg_id = arg_ids[arg_ix]\n",
    "\n",
    "                                if arg_ix == 0:\n",
    "                                    if len(arg_ids) == 1:\n",
    "                                        arg_label = 'S-arg'+str(n)\n",
    "                                    else:\n",
    "                                        arg_label = 'B-arg'+str(n)\n",
    "                                else:\n",
    "                                    arg_label = 'I-arg'+str(n)\n",
    "\n",
    "\n",
    "                                sent[arg_id][-1] = arg_label\n",
    "\n",
    "                            n += 1\n",
    "        for i in new_conll_with_frame:\n",
    "            arg_id_result = ko_arg_ider.identifier(i, argid_model)\n",
    "            result.append(arg_id_result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplization(text, conll_with_frame, frame_scores, arg_id_result):\n",
    "    triples = []\n",
    "    for sent_ix in range(len(conll_with_frame)):\n",
    "        sent = conll_with_frame[sent_ix]\n",
    "        frame = None\n",
    "        for token in sent:\n",
    "            if token[13] != '_':\n",
    "                lu = token[12]\n",
    "                frame = token[13]\n",
    "        if frame != None:\n",
    "            triple = (frame, 'frdf:lu', lu, frame_scores[sent_ix])\n",
    "            triples.append(triple)\n",
    "            \n",
    "            args = arg_id_result[sent_ix]\n",
    "            for arg in args:\n",
    "                arg_span, arg_label, arg_score = arg[0],arg[1],arg[2]\n",
    "\n",
    "                arg_score = arg_score.item()*0.1\n",
    "\n",
    "                tokens = text.split(' ')\n",
    "                arg_text = ' '.join(tokens[arg_span['begin']:arg_span['end']])\n",
    "                triple = (frame, 'fe:'+arg_label, arg_text, arg_score)\n",
    "                \n",
    "                triples.append(triple)\n",
    "                \n",
    "    for t in triples:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Activity_finish', 'frdf:lu', '마치다.v', 0.47654213905334475)\n",
      "('Activity_finish', 'fe:Activity', '고등학교를', 0.8616240501403809)\n",
      "('Activity_finish', 'fe:Activity', '이후', 0.8054991722106934)\n",
      "('Time_vector', 'frdf:lu', '이후.n', 0.9333463668823243)\n",
      "('Origin', 'frdf:lu', '이탈리아.n', 1.0)\n",
      "('Military', 'frdf:lu', '군대.n', 0.48384027481079106)\n",
      "('Time_vector', 'frdf:lu', '전.n', 0.9590445518493653)\n",
      "('Calendric_unit', 'frdf:lu', '달.n', 0.47250165939331057)\n",
      "('Statement', 'frdf:lu', '말.n', 0.18432452678680422)\n",
      "('Text', 'frdf:lu', '기사.n', 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./src/frameid_module_ko.py:346: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  embeds, self.hidden_lstm_1)\n",
      "./src/frameid_module_ko.py:352: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  target_lstm, self.hidden_lstm_2)\n",
      "./src/argid_module_ko.py:249: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  embeds, self.hidden_lstm_tok)\n",
      "./src/argid_module_ko.py:255: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  target_lstm, self.hidden_lstm_tgt)\n",
      "./src/argid_module_ko.py:268: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  arg_lstm, self.hidden_lstm_arg)\n"
     ]
    }
   ],
   "source": [
    "def korean_frame_parsing(nlp):\n",
    "    conll_with_target = target_identification(conll, language)\n",
    "    conll_with_frame, frame_scores = frame_identification(conll_with_target, language)\n",
    "    arg_id_result = arg_identification(conll_with_frame, language)\n",
    "    \n",
    "#     print(arg_id_result)\n",
    "    \n",
    "    text = nlp[0]['text']\n",
    "    triplization(text, conll_with_frame, frame_scores, arg_id_result)\n",
    "    \n",
    "    \n",
    "    return arg_id_result\n",
    "\n",
    "# text = '헤밍웨이는 고등학교를 마친 이후 이탈리아의 전방 군대에 입대하여 구급차 운전사가 되기 전에 캔자스시티스타에서 몇 달 동안 기사를 썼다.'\n",
    "# nlp = etri.getETRI(text)\n",
    "# conll, pa = read_nlp(nlp)\n",
    "# result = korean_frame_parsing(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', 'There', '_', 'there', 'EX', 'EX', '0', '_', '_', '_', '_', '_', '_', '_'], ['2', \"'s\", '_', 'be', 'VBZ', 'VBZ', '0', '_', '_', '_', '_', '_', '_', '_'], ['3', 'nothing', '_', 'nothing', 'NN', 'NN', '0', '_', '_', '_', '_', '_', '_', '_'], ['4', 'to', '_', 'to', 'TO', 'TO', '0', '_', '_', '_', '_', '_', '_', '_'], ['5', 'tell', '_', 'tell', 'VB', 'VB', '0', '_', '_', '_', '_', '_', 'tell.v', 'TARGET'], ['6', '!', '_', '!', '.', '.', '0', '_', '_', '_', '_', '_', '_', '_']]\n",
      "[['1', 'He', '_', 'he', 'PRP', 'PRP', '0', '_', '_', '_', '_', '_', '_', '_'], ['2', \"'s\", '_', 'be', 'VBZ', 'VBZ', '0', '_', '_', '_', '_', '_', '_', '_'], ['3', 'just', '_', 'just', 'RB', 'RB', '0', '_', '_', '_', '_', '_', '_', '_'], ['4', 'some', '_', 'some', 'DT', 'DT', '0', '_', '_', '_', '_', '_', '_', '_'], ['5', 'guy', '_', 'guy', 'NN', 'NN', '0', '_', '_', '_', '_', '_', 'guy.n', 'TARGET'], ['6', 'I', '_', 'I', 'PRP', 'PRP', '0', '_', '_', '_', '_', '_', '_', '_'], ['7', 'work', '_', 'work', 'VBP', 'VBP', '0', '_', '_', '_', '_', '_', '_', '_'], ['8', 'with', '_', 'with', 'IN', 'IN', '0', '_', '_', '_', '_', '_', '_', '_'], ['9', '!', '_', '!', '.', '.', '0', '_', '_', '_', '_', '_', '_', '_']]\n",
      "[['1', 'He', '_', 'he', 'PRP', 'PRP', '0', '_', '_', '_', '_', '_', '_', '_'], ['2', \"'s\", '_', 'be', 'VBZ', 'VBZ', '0', '_', '_', '_', '_', '_', '_', '_'], ['3', 'just', '_', 'just', 'RB', 'RB', '0', '_', '_', '_', '_', '_', '_', '_'], ['4', 'some', '_', 'some', 'DT', 'DT', '0', '_', '_', '_', '_', '_', '_', '_'], ['5', 'guy', '_', 'guy', 'NN', 'NN', '0', '_', '_', '_', '_', '_', '_', '_'], ['6', 'I', '_', 'I', 'PRP', 'PRP', '0', '_', '_', '_', '_', '_', '_', '_'], ['7', 'work', '_', 'work', 'VBP', 'VBP', '0', '_', '_', '_', '_', '_', 'work.v', 'TARGET'], ['8', 'with', '_', 'with', 'IN', 'IN', '0', '_', '_', '_', '_', '_', '_', '_'], ['9', '!', '_', '!', '.', '.', '0', '_', '_', '_', '_', '_', '_', '_']]\n",
      "[['1', \"C'mon\", '_', \"c'mon\", 'VB', 'VB', '0', '_', '_', '_', '_', '_', '_', '_'], ['2', ',', '_', ',', ',', ',', '0', '_', '_', '_', '_', '_', '_', '_'], ['3', 'you', '_', 'you', 'PRP', 'PRP', '0', '_', '_', '_', '_', '_', '_', '_'], ['4', \"'re\", '_', 'be', 'VBP', 'VBP', '0', '_', '_', '_', '_', '_', '_', '_'], ['5', 'going', '_', 'go', 'VBG', 'VBG', '0', '_', '_', '_', '_', '_', 'go.v', 'TARGET'], ['6', 'out', '_', 'out', 'RP', 'RP', '0', '_', '_', '_', '_', '_', '_', '_'], ['7', 'with', '_', 'with', 'IN', 'IN', '0', '_', '_', '_', '_', '_', '_', '_'], ['8', 'the', '_', 'the', 'DT', 'DT', '0', '_', '_', '_', '_', '_', '_', '_'], ['9', 'guy', '_', 'guy', 'NN', 'NN', '0', '_', '_', '_', '_', '_', '_', '_'], ['10', '!', '_', '!', '.', '.', '0', '_', '_', '_', '_', '_', '_', '_']]\n",
      "[['1', \"C'mon\", '_', \"c'mon\", 'VB', 'VB', '0', '_', '_', '_', '_', '_', '_', '_'], ['2', ',', '_', ',', ',', ',', '0', '_', '_', '_', '_', '_', '_', '_'], ['3', 'you', '_', 'you', 'PRP', 'PRP', '0', '_', '_', '_', '_', '_', '_', '_'], ['4', \"'re\", '_', 'be', 'VBP', 'VBP', '0', '_', '_', '_', '_', '_', '_', '_'], ['5', 'going', '_', 'go', 'VBG', 'VBG', '0', '_', '_', '_', '_', '_', '_', '_'], ['6', 'out', '_', 'out', 'RP', 'RP', '0', '_', '_', '_', '_', '_', '_', '_'], ['7', 'with', '_', 'with', 'IN', 'IN', '0', '_', '_', '_', '_', '_', '_', '_'], ['8', 'the', '_', 'the', 'DT', 'DT', '0', '_', '_', '_', '_', '_', '_', '_'], ['9', 'guy', '_', 'guy', 'NN', 'NN', '0', '_', '_', '_', '_', '_', 'guy.n', 'TARGET'], ['10', '!', '_', '!', '.', '.', '0', '_', '_', '_', '_', '_', '_', '_']]\n",
      "[['1', 'There', '_', 'there', 'EX', 'EX', '0', '_', '_', '_', '_', '_', '_', '_'], ['2', \"'s\", '_', 'be', 'VBZ', 'VBZ', '0', '_', '_', '_', '_', '_', '_', '_'], ['3', 'got', '_', 'get', 'VBN', 'VBN', '0', '_', '_', '_', '_', '_', 'get.v', 'TARGET'], ['4', 'ta', '_', 'ta', 'TO', 'TO', '0', '_', '_', '_', '_', '_', '_', '_'], ['5', 'be', '_', 'be', 'VB', 'VB', '0', '_', '_', '_', '_', '_', '_', '_'], ['6', 'something', '_', 'something', 'NN', 'NN', '0', '_', '_', '_', '_', '_', '_', '_'], ['7', 'wrong', '_', 'wrong', 'JJ', 'JJ', '0', '_', '_', '_', '_', '_', '_', '_'], ['8', 'with', '_', 'with', 'IN', 'IN', '0', '_', '_', '_', '_', '_', '_', '_'], ['9', 'him', '_', 'he', 'PRP', 'PRP', '0', '_', '_', '_', '_', '_', '_', '_'], ['10', '!', '_', '!', '.', '.', '0', '_', '_', '_', '_', '_', '_', '_']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./src/frameid_module_en.py:346: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  embeds, self.hidden_lstm_1)\n",
      "./src/frameid_module_en.py:352: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  target_lstm, self.hidden_lstm_2)\n"
     ]
    }
   ],
   "source": [
    "from frameid_module_en import LSTMTagger\n",
    "en_fid_model = torch.load(fid_model_en_dir)\n",
    "en_frame_ider = frameid_module_en.frame_identifier()\n",
    "\n",
    "def en_frame_identification():\n",
    "    with open('./test.conll') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    conll_orig = []\n",
    "    sent = []\n",
    "    for line in lines:\n",
    "        line = line.rstrip('\\n')\n",
    "        if line.startswith('#'):          \n",
    "            pass\n",
    "        else:\n",
    "            if line != '':\n",
    "                token = line.split('\\t')\n",
    "                sent.append(token)\n",
    "            else:\n",
    "                conll_orig.append(sent)\n",
    "                sent = []\n",
    " \n",
    "    conll = []\n",
    "    for sent in conll_orig:\n",
    "        \n",
    "        new_sent = []\n",
    "        token_ix = 1\n",
    "        for token in sent:\n",
    "            new_token = []\n",
    "            new_token.append(str(token_ix))\n",
    "            new_token.append(token[3])\n",
    "            new_token.append('_')\n",
    "            new_token.append(token[6])\n",
    "            new_token.append(token[4])\n",
    "            new_token.append(token[4])\n",
    "            new_token.append('0')\n",
    "            new_token.append('_')\n",
    "            new_token.append('_')\n",
    "            new_token.append('_')\n",
    "            new_token.append('_')\n",
    "            new_token.append('_')\n",
    "            new_sent.append(new_token)\n",
    "            \n",
    "            token_ix += 1\n",
    "            \n",
    "        conll.append(new_sent)\n",
    "    \n",
    "    conll_with_target = []\n",
    "    for sent in conll:\n",
    "\n",
    "        d = target_identification(sent, 'en')\n",
    "        conll_with_target.append(d[0])\n",
    "\n",
    "        \n",
    "\n",
    "    result = []\n",
    "    scores = []\n",
    "    for conll in conll_with_target:\n",
    "\n",
    "\n",
    "        frame, score = en_frame_ider.identifier(conll, en_fid_model)\n",
    "        if frame != '_':\n",
    "            score = score.item()*0.1\n",
    "            new_conll = deepcopy(conll)\n",
    "            for token in new_conll:\n",
    "                if token[12] != '_':\n",
    "                    token[13] = frame\n",
    "                else:\n",
    "                    pass\n",
    "            result.append(new_conll)\n",
    "            scores.append(score)\n",
    "    return result, scores     \n",
    "        \n",
    "            \n",
    "# result, scores = en_frame_identification()\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
